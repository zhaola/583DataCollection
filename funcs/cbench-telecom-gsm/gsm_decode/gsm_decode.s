	.text
	.file	"gsm_decode.c"
	.globl	gsm_decode              # -- Begin function gsm_decode
	.p2align	4, 0x90
	.type	gsm_decode,@function
gsm_decode:                             # @gsm_decode
	.cfi_startproc
# %bb.0:                                # %"0"
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	subq	$208, %rsp
	movq	%rdi, -192(%rbp)
	movq	%rsi, -8(%rbp)
	movq	%rdx, -184(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$15, %eax
	cmpl	$13, %eax
	je	.LBB0_2
# %bb.1:                                # %"1"
	movq	__profc_gsm_decode, %rax
	addq	$1, %rax
	movq	%rax, __profc_gsm_decode
	movl	$-1, -52(%rbp)
	jmp	.LBB0_3
.LBB0_2:                                # %"2"
	leaq	-160(%rbp), %r10
	leaq	-16(%rbp), %r9
	leaq	-168(%rbp), %r8
	leaq	-24(%rbp), %rcx
	leaq	-176(%rbp), %rdx
	leaq	-48(%rbp), %rsi
	movq	__profc_gsm_decode+8, %rdi
	addq	$1, %rdi
	movq	%rdi, __profc_gsm_decode+8
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$15, %eax
	shll	$2, %eax
	movw	%ax, -48(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-48(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -48(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$63, %eax
	movw	%ax, -46(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$31, %eax
	movw	%ax, -44(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$7, %eax
	shll	$2, %eax
	movw	%ax, -42(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-42(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -42(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$2, %eax
	andl	$15, %eax
	movw	%ax, -40(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$3, %eax
	shll	$2, %eax
	movw	%ax, -38(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-38(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -38(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, -36(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, -34(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$127, %eax
	movw	%ax, -176(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$1, %eax
	movw	%ax, -24(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-24(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -24(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$3, %eax
	movw	%ax, -168(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$31, %eax
	shll	$1, %eax
	movw	%ax, -16(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-16(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -16(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, -160(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, -158(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, -156(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-156(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -156(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, -154(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, -152(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$7, %eax
	movw	%ax, -150(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$2, %eax
	andl	$7, %eax
	movw	%ax, -148(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$3, %eax
	shll	$1, %eax
	movw	%ax, -146(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-146(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -146(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, -144(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, -142(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, -140(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-140(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -140(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, -138(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, -136(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$127, %eax
	movw	%ax, -174(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$1, %eax
	movw	%ax, -22(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-22(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -22(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$3, %eax
	movw	%ax, -166(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$31, %eax
	shll	$1, %eax
	movw	%ax, -14(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-14(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -14(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, -134(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, -132(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, -130(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-130(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -130(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, -128(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, -126(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$7, %eax
	movw	%ax, -124(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$2, %eax
	andl	$7, %eax
	movw	%ax, -122(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$3, %eax
	shll	$1, %eax
	movw	%ax, -120(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-120(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -120(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, -118(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, -116(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, -114(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-114(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -114(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, -112(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, -110(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$127, %eax
	movw	%ax, -172(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$1, %eax
	movw	%ax, -20(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-20(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -20(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$3, %eax
	movw	%ax, -164(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$31, %eax
	shll	$1, %eax
	movw	%ax, -12(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-12(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -12(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, -108(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, -106(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, -104(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-104(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -104(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, -102(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, -100(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$7, %eax
	movw	%ax, -98(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$2, %eax
	andl	$7, %eax
	movw	%ax, -96(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$3, %eax
	shll	$1, %eax
	movw	%ax, -94(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-94(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -94(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, -92(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, -90(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, -88(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-88(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -88(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, -86(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, -84(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$127, %eax
	movw	%ax, -170(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$1, %eax
	movw	%ax, -18(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-18(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -18(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$3, %eax
	movw	%ax, -162(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$31, %eax
	shll	$1, %eax
	movw	%ax, -10(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-10(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -10(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, -82(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, -80(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, -78(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-78(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -78(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, -76(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, -74(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$7, %eax
	movw	%ax, -72(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$2, %eax
	andl	$7, %eax
	movw	%ax, -70(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$3, %eax
	shll	$1, %eax
	movw	%ax, -68(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	-68(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -68(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, -66(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, -64(%rbp)
	movq	-8(%rbp), %rax
	movq	%rax, %rdi
	addq	$1, %rdi
	movq	%rdi, -8(%rbp)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, -62(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	-62(%rbp), %edi
	orl	%eax, %edi
	movw	%di, -62(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, -60(%rbp)
	movq	-8(%rbp), %rax
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, -58(%rbp)
	movq	-192(%rbp), %rdi
	movq	-184(%rbp), %rax
	movq	%r10, (%rsp)
	movq	%rax, 8(%rsp)
	callq	Gsm_Decoder
	movl	$0, -52(%rbp)
.LBB0_3:                                # %"3"
	movl	-52(%rbp), %eax
	addq	$208, %rsp
	popq	%rbp
	.cfi_def_cfa %rsp, 8
	retq
.Lfunc_end0:
	.size	gsm_decode, .Lfunc_end0-gsm_decode
	.cfi_endproc
                                        # -- End function
	.hidden	__profc_gsm_decode
	.ident	"clang version 10.0.0 "
	.section	".note.GNU-stack","",@progbits
