	.text
	.file	"gsm_decode.c"
	.globl	gsm_decode.2            # -- Begin function gsm_decode.2
	.p2align	4, 0x90
	.type	gsm_decode.2,@function
gsm_decode.2:                           # @gsm_decode.2
	.cfi_startproc
# %bb.0:                                # %newFuncRoot
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	subq	$24, %rsp
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movq	40(%rbp), %r14
	movq	32(%rbp), %r10
	movq	24(%rbp), %r11
	movq	16(%rbp), %r15
	jmp	.LBB0_2
.LBB0_1:                                # %"3.exitStub"
	addq	$24, %rsp
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	.cfi_def_cfa %rsp, 8
	retq
.LBB0_2:                                # %"2"
	.cfi_def_cfa %rbp, 16
	movq	__profc_gsm_decode+8, %rbx
	addq	$1, %rbx
	movq	%rbx, __profc_gsm_decode+8
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$15, %eax
	shll	$2, %eax
	movw	%ax, (%rsi)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	(%rsi), %ebx
	orl	%eax, %ebx
	movw	%bx, (%rsi)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$63, %eax
	movw	%ax, 2(%rsi)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$31, %eax
	movw	%ax, 4(%rsi)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$7, %eax
	shll	$2, %eax
	movw	%ax, 6(%rsi)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	6(%rsi), %ebx
	orl	%eax, %ebx
	movw	%bx, 6(%rsi)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$2, %eax
	andl	$15, %eax
	movw	%ax, 8(%rsi)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$3, %eax
	shll	$2, %eax
	movw	%ax, 10(%rsi)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	10(%rsi), %ebx
	orl	%eax, %ebx
	movw	%bx, 10(%rsi)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, 12(%rsi)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, 14(%rsi)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$127, %eax
	movw	%ax, (%rdx)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$1, %eax
	movw	%ax, (%rcx)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	(%rcx), %ebx
	orl	%eax, %ebx
	movw	%bx, (%rcx)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$3, %eax
	movw	%ax, (%r8)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$31, %eax
	shll	$1, %eax
	movw	%ax, (%r9)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	(%r9), %ebx
	orl	%eax, %ebx
	movw	%bx, (%r9)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, (%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, 2(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, 4(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	4(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 4(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, 6(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, 8(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$7, %eax
	movw	%ax, 10(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$2, %eax
	andl	$7, %eax
	movw	%ax, 12(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$3, %eax
	shll	$1, %eax
	movw	%ax, 14(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	14(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 14(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, 16(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, 18(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, 20(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	20(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 20(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, 22(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, 24(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$127, %eax
	movw	%ax, 2(%rdx)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$1, %eax
	movw	%ax, 2(%rcx)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	2(%rcx), %ebx
	orl	%eax, %ebx
	movw	%bx, 2(%rcx)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$3, %eax
	movw	%ax, 2(%r8)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$31, %eax
	shll	$1, %eax
	movw	%ax, 2(%r9)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	2(%r9), %ebx
	orl	%eax, %ebx
	movw	%bx, 2(%r9)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, 26(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, 28(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, 30(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	30(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 30(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, 32(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, 34(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$7, %eax
	movw	%ax, 36(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$2, %eax
	andl	$7, %eax
	movw	%ax, 38(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$3, %eax
	shll	$1, %eax
	movw	%ax, 40(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	40(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 40(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, 42(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, 44(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, 46(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	46(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 46(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, 48(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, 50(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$127, %eax
	movw	%ax, 4(%rdx)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$1, %eax
	movw	%ax, 4(%rcx)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	4(%rcx), %ebx
	orl	%eax, %ebx
	movw	%bx, 4(%rcx)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$3, %eax
	movw	%ax, 4(%r8)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$31, %eax
	shll	$1, %eax
	movw	%ax, 4(%r9)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	4(%r9), %ebx
	orl	%eax, %ebx
	movw	%bx, 4(%r9)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, 52(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, 54(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, 56(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	56(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 56(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, 58(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, 60(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$7, %eax
	movw	%ax, 62(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$2, %eax
	andl	$7, %eax
	movw	%ax, 64(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$3, %eax
	shll	$1, %eax
	movw	%ax, 66(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	66(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 66(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, 68(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, 70(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, 72(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	72(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 72(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, 74(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, 76(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$127, %eax
	movw	%ax, 6(%rdx)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$1, %eax
	movw	%ax, 6(%rcx)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	6(%rcx), %ebx
	orl	%eax, %ebx
	movw	%bx, 6(%rcx)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$3, %eax
	movw	%ax, 6(%r8)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$31, %eax
	shll	$1, %eax
	movw	%ax, 6(%r9)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	6(%r9), %ebx
	orl	%eax, %ebx
	movw	%bx, 6(%r9)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, 78(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, 80(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, 82(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	82(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 82(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, 84(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, 86(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$5, %eax
	andl	$7, %eax
	movw	%ax, 88(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$2, %eax
	andl	$7, %eax
	movw	%ax, 90(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$3, %eax
	shll	$1, %eax
	movw	%ax, 92(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$7, %eax
	andl	$1, %eax
	movswl	92(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 92(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$4, %eax
	andl	$7, %eax
	movw	%ax, 94(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$1, %eax
	andl	$7, %eax
	movw	%ax, 96(%r15)
	movq	(%rdi), %rax
	movq	%rax, %rbx
	addq	$1, %rbx
	movq	%rbx, (%rdi)
	movzbl	(%rax), %eax
	andl	$1, %eax
	shll	$2, %eax
	movw	%ax, 98(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$6, %eax
	andl	$3, %eax
	movswl	98(%r15), %ebx
	orl	%eax, %ebx
	movw	%bx, 98(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	sarl	$3, %eax
	andl	$7, %eax
	movw	%ax, 100(%r15)
	movq	(%rdi), %rax
	movzbl	(%rax), %eax
	andl	$7, %eax
	movw	%ax, 102(%r15)
	movq	(%r11), %rdi
	movq	(%r10), %rax
	movq	%r15, (%rsp)
	movq	%rax, 8(%rsp)
	callq	Gsm_Decoder
	movl	$0, (%r14)
	jmp	.LBB0_1
.Lfunc_end0:
	.size	gsm_decode.2, .Lfunc_end0-gsm_decode.2
	.cfi_endproc
                                        # -- End function
	.hidden	__profc_gsm_decode
	.ident	"clang version 10.0.0 "
	.section	".note.GNU-stack","",@progbits
